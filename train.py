import jsonimport osimport torchimport torch.utils.data as dataimport randomfrom torch.utils.data import DataLoaderfrom torchvision.transforms import transformsfrom torch.utils.tensorboard import SummaryWriterfrom sklearn.metrics import confusion_matrixfrom PIL import Imageimport numpy as npfrom model_cct import cct_6_7x3_64_sine, cct_6_3x6_64_sinefrom model_cct import cct_4_3x6_64_sinefrom model_cct.multiBranch import MultiBranchfrom noisyTransform import AddNoise, SaltPepperNoise, GaussianNoisefrom model_cct.BCRN import BCRNfrom model_cct.VDCNN import VDCNNfrom model_cct.MultiViewTransformer import MultiViewTransformeros.environ["CUDA_VISIBLE_DEVICES"] = "0"device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")# device = 'cpu'imagebuffer = {}class Dataset(data.Dataset):    def __init__(self,path,transform = None):        self.path = path        self.transform = transform        self.image = []        # get label        self.class_names = sorted(os.listdir(path))        self.names2index = {v: k for k, v in enumerate(self.class_names)}        # read-in sequence and label        for label in self.class_names:            labelPath = os.path.join(path,label)            jsonpath = os.path.join(labelPath,"sequence.json")            with open(jsonpath, 'r', encoding='utf-8') as f:                sequence = json.load(f)            for i in range(0, len(sequence)):                self.image.append((sequence[i], self.names2index[label]))    def __len__(self):        return len(self.image)    def __getitem__(self, item):        path,label = self.image[item]        img = []        for i in range(0, len(path)):            if path[i] not in imagebuffer:                imagebuffer[path[i]] = Image.open(path[i])            tmp = imagebuffer[path[i]]            img.append(self.transform(tmp))        return torch.cat(tuple(img)).to(device), label# for EOC-C or EOC-V testclass TestDataset(data.Dataset):    def __init__(self,path,transform = None):        self.path = path        self.transform = transform        self.image = []        # get type        self.type_names = sorted(os.listdir(path))        self.names2index = {v: k for k, v in enumerate(self.type_names)}        self.label2idxes = {}        # read-in sequence and label        for type in self.type_names:            self.label2idxes[type] = []            typePath = os.path.join(path,type)            jsonpath = os.path.join(typePath,"sequence.json")            with open(jsonpath, 'r', encoding='utf-8') as f:                sequence = json.load(f)            # for EOC-C            if type == 'SN_9566' or type == 'SN_C21':                for i in range(0, len(sequence)):                    self.image.append((sequence[i], 0))                    self.label2idxes[type].append(len(self.image) - 1)            else:                for i in range(0, len(sequence)):                    self.image.append((sequence[i], 3))                    self.label2idxes[type].append(len(self.image)-1)            #for EOC-V            # for i in range(0, len(sequence)):            #     self.image.append((sequence[i], 3))    def __len__(self):        return len(self.image)    def __getitem__(self, item):        path,label = self.image[item]        img = []        for i in range(0, len(path)):            if path[i] not in imagebuffer:                imagebuffer[path[i]] = Image.open(path[i])            tmp = imagebuffer[path[i]]            img.append(self.transform(tmp))        return torch.cat(tuple(img)), labeldef filtered_confusion_matrix(label2idxes, true, pred):    for label, idxes in label2idxes.items():        mpred = pred[idxes].numpy().astype(int)        values, counts = np.unique(mpred, return_counts=True)        print("\nlabel:{}({})".format(label, int(true[idxes[0]])))        for i in range(len(values)):            print("label:", values[i], "count:", counts[i], end=', ')        print("")def train_model(model,train_loader, valid_loader, criterion, optimizer, writer, num_epochs=20, scheduler = None, model_name = "", label2idxes = None):    def train(model, train_loader,optimizer,criterion):        model.train(True)        total_loss = 0.0        total_correct = 0        for inputs, labels in train_loader:            inputs = inputs.to(device)            labels = labels.to(device)            optimizer.zero_grad()            outputs = model(inputs)            loss = criterion(outputs, labels)            _, predictions = torch.max(outputs, 1)            loss.backward()            optimizer.step()            total_loss += loss.item() * inputs.size(0)            total_correct += torch.sum(predictions == labels.data)        epoch_loss = total_loss / len(train_loader.dataset)        epoch_acc = total_correct.double() / len(train_loader.dataset)        return epoch_loss, epoch_acc.item()    def valid(model, valid_loader,criterion):        model.train(False)        total_loss = 0.0        total_correct = 0        true = (torch.tensor([])).to(device)        pred = (torch.tensor([])).to(device)        for inputs, labels in valid_loader:            inputs = inputs.to(device)            labels = labels.to(device)            outputs = model(inputs)            loss = criterion(outputs, labels)            _, predictions = torch.max(outputs, 1)            total_loss += loss.item() * inputs.size(0)            total_correct += torch.sum(predictions == labels.data)            true = torch.cat((true,labels.data),0)            pred = torch.cat((pred,predictions),0)        epoch_loss = total_loss / len(valid_loader.dataset)        epoch_acc = total_correct.double() / len(valid_loader.dataset)        # return epoch_loss, epoch_acc.item()        return epoch_loss, epoch_acc.item(), true, pred    best_acc = 0.0    base_epoch = 0    for epoch in range(base_epoch, base_epoch+num_epochs):        print('*' * 100)        print('epoch:{:d}/{:d}'.format(epoch, base_epoch + num_epochs))        train_loss, train_acc = train(model, train_loader,optimizer,criterion)        print("training: {:.4f}, {:.4f}".format(train_loss, train_acc))        valid_loss, valid_acc, valid_true, valid_pred= valid(model, valid_loader,criterion)        # valid_loss, valid_acc= valid(model, valid_loader, criterion)        print("validation: {:.4f}, {:.4f}".format(valid_loss, valid_acc))        valid_true = valid_true.cpu()        valid_pred = valid_pred.cpu()        print("confusion_matrix: \n",confusion_matrix(valid_true,valid_pred))        if label2idxes is not None:            print("filtered confusion matrix: \n")            filtered_confusion_matrix(label2idxes, valid_true, valid_pred)        if writer != None:            writer.add_scalar('Loss/test', valid_loss, epoch)            writer.add_scalar('Loss/train', train_loss, epoch)            writer.add_scalar('Accuracy/test', valid_acc, epoch)            writer.add_scalar('Accuracy/train', train_acc, epoch)        if scheduler:            scheduler.step()        if valid_acc >= best_acc:            best_acc = valid_acc            best_model = model            best_cm = confusion_matrix(valid_true,valid_pred)            if label2idxes is not None:                print("filtered confusion matrix: \n")                filtered_confusion_matrix(label2idxes, valid_true, valid_pred)            torch.save(best_model, 'best_model/SOC/{}.pt'.format(model_name))    print('*' * 100)    print('best acc: {:.4f}'.format(best_acc))    print("best confusion_matrix: \n", best_cm)def valid_model(model, valid_loader, criterion):    def valid(model, valid_loader,criterion):        model.train(False)        total_loss = 0.0        total_correct = 0        true = (torch.tensor([])).to(device)        pred = (torch.tensor([])).to(device)        for inputs, labels in valid_loader:            inputs = inputs.to(device)            labels = labels.to(device)            outputs = model(inputs)            loss = criterion(outputs, labels)            _, predictions = torch.max(outputs, 1)            total_loss += loss.item() * inputs.size(0)            total_correct += torch.sum(predictions == labels.data)            true = torch.cat((true,labels.data),0)            pred = torch.cat((pred,predictions),0)        epoch_loss = total_loss / len(valid_loader.dataset)        epoch_acc = total_correct.double() / len(valid_loader.dataset)        # return epoch_loss, epoch_acc.item()        return epoch_loss, epoch_acc.item(), true, pred    valid_loss, valid_acc, valid_true, valid_pred = valid(model, valid_loader, criterion)    valid_true = valid_true.cpu()    valid_pred = valid_pred.cpu()    print("validation: {:.4f}, {:.4f}".format(valid_loss, valid_acc))    print("confusion_matrix: \n", confusion_matrix(valid_true, valid_pred))def setup_seed(seed):    torch.manual_seed(seed)    torch.cuda.manual_seed_all(seed)    np.random.seed(seed)    random.seed(seed)    torch.backends.cudnn.deterministic = Trueif __name__ == '__main__':    # model = cct_6_3x6_64_sine()    trainTransforms = transforms.Compose([        # transforms.Resize([224, 224]),        # transforms.RandomResizedCrop(64, scale=(0.9, 1.0), ratio=(0.9, 1.1)),        # transforms.RandomHorizontalFlip(),        transforms.ToTensor(),        # AddNoise(noise_rate=0.01),        transforms.CenterCrop(size=64),    ])    validTransforms = transforms.Compose([        # transforms.Resize([224, 224]),        # transforms.RandomResizedCrop(64, scale=(0.9, 1.0), ratio=(0.9, 1.1)),        # transforms.RandomHorizontalFlip(),        transforms.ToTensor(),        GaussianNoise(noise_rate=0.01),        transforms.CenterCrop(size=64),    ])    train_data = Dataset('./data/SOC-128/train', transform=trainTransforms)    valid_data = Dataset('./data/SOC-128/test', transform=validTransforms)    # valid_data = TestDataset('./data/EOC-C/test', transform=validTransforms)    # label2idxes = valid_data.label2idxes    BATCH_SIZE = 32    train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)    valid_loader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=False)    setup_seed(326)    # for train    # model = cct_6_7x3_64_sine(num_classes = 10, n_input_channels = 1)    model = MultiViewTransformer(n_input_size=64, n_input_channels=1, n_output_channels=256)    # model = VDCNN()    # model = MultiBranch()    # for noise-test    # model = torch.load('best_model/SOC/noisy_seed1_cct_6_7x3_64_sine_3.pt')    model = model.to(device)    criterion = torch.nn.CrossEntropyLoss()    epoch = 100    lr = 0.001    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5, last_epoch=-1)    # milestones=[10,30]    # scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones, gamma=0.1, last_epoch=-1)    writer = SummaryWriter('runs/SOC/MultiViewTransformer')    train_model(model, train_loader, valid_loader, criterion, optimizer, writer, num_epochs=epoch, scheduler=scheduler, model_name='MultiViewTransformer', label2idxes=None)    writer.close()    # for noise-test    # for seed in [2,100,304,326,1011]:    #     print("seed =", seed)    #     for noise_rate_idx in range(15):    #         noise_rate = (noise_rate_idx+1)/100    #         validTransforms = transforms.Compose([    #             # transforms.Resize([224, 224]),    #             # transforms.RandomResizedCrop(64, scale=(0.9, 1.0), ratio=(0.9, 1.1)),    #             # transforms.RandomHorizontalFlip(),    #             transforms.ToTensor(),    #             GaussianNoise(noise_rate=noise_rate),    #             transforms.CenterCrop(size=64),    #         ])    #         setup_seed(seed)    #         valid_data = Dataset('./data/SOC-128/test', transform=validTransforms)    #         valid_loader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=False)    #         print("=========================================")    #         print("noise_rate =", noise_rate, "seed =", seed)    #         valid_model(model, valid_loader, criterion)    #         print("=========================================\n\n")