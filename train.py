import jsonimport osimport torchimport torch.utils.data as dataimport randomfrom torch.utils.data import DataLoaderfrom torchvision.transforms import transformsfrom torch.utils.tensorboard import SummaryWriterfrom sklearn.metrics import confusion_matrixfrom PIL import Imagefrom collections import OrderedDictimport numpy as npfrom model_cct import cct_6_7x3_64_sineos.environ["CUDA_VISIBLE_DEVICES"] = "0"device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")# device = 'cpu'imagebuffer = {}class Dataset(data.Dataset):    def __init__(self,path,transform = None, percent = 1.0, seed = 1):        self.path = path        self.transform = transform        self.image = []        # get label        self.class_names = sorted(os.listdir(path))        self.names2index = {v: k for k, v in enumerate(self.class_names)}        setup_seed(seed)        # read-in sequence and label        for label in self.class_names:            labelPath = os.path.join(path,label)            jsonpath = os.path.join(labelPath,"sequence.json")            with open(jsonpath, 'r', encoding='utf-8') as f:                sequence = json.load(f)            selectedSequence = np.random.choice(len(sequence), int(len(sequence)*percent), replace=False)            for i in selectedSequence:                self.image.append((sequence[i], self.names2index[label]))    def __len__(self):        return len(self.image)    def __getitem__(self, item):        path,label = self.image[item]        img = []        for i in range(0, len(path)):            if path[i] not in imagebuffer:                imagebuffer[path[i]] = Image.open(path[i])            tmp = imagebuffer[path[i]]            img.append(self.transform(tmp))        return torch.cat(tuple(img)).to(device), label# for EOC-C or EOC-V testclass TestDataset(data.Dataset):    def __init__(self,path,transform = None):        self.path = path        self.transform = transform        self.image = []        # get type        self.type_names = sorted(os.listdir(path))        self.names2index = {v: k for k, v in enumerate(self.type_names)}        self.label2idxes = {}        # read-in sequence and label        for type in self.type_names:            self.label2idxes[type] = []            typePath = os.path.join(path,type)            jsonpath = os.path.join(typePath,"sequence.json")            with open(jsonpath, 'r', encoding='utf-8') as f:                sequence = json.load(f)            # for EOC-C            if type == 'SN_9566' or type == 'SN_C21':                for i in range(0, len(sequence)):                    self.image.append((sequence[i], 0))                    self.label2idxes[type].append(len(self.image) - 1)            else:                for i in range(0, len(sequence)):                    self.image.append((sequence[i], 3))                    self.label2idxes[type].append(len(self.image)-1)            #for EOC-V            # for i in range(0, len(sequence)):            #     self.image.append((sequence[i], 3))            #     self.label2idxes[type].append(len(self.image) - 1)    def __len__(self):        return len(self.image)    def __getitem__(self, item):        path,label = self.image[item]        img = []        for i in range(0, len(path)):            if path[i] not in imagebuffer:                imagebuffer[path[i]] = Image.open(path[i])            tmp = imagebuffer[path[i]]            img.append(self.transform(tmp))        return torch.cat(tuple(img)), labeldef filtered_confusion_matrix(label2idxes, true, pred):    for label, idxes in label2idxes.items():        mpred = pred[idxes].numpy().astype(int)        values, counts = np.unique(mpred, return_counts=True)        print("\nlabel:{}({})".format(label, int(true[idxes[0]])))        for i in range(len(values)):            print("label:", values[i], "count:", counts[i], end=', ')        print("")def train_model(model,train_loader, valid_loader, criterion, optimizer, writer, num_epochs=20, scheduler = None, model_name = "", label2idxes = None):    def train(model, train_loader,optimizer,criterion):        model.train(True)        total_loss = 0.0        total_correct = 0        for inputs, labels in train_loader:            inputs = inputs.to(device)            labels = labels.to(device)            optimizer.zero_grad()            outputs = model(inputs)            loss = criterion(outputs, labels)            _, predictions = torch.max(outputs, 1)            loss.backward()            optimizer.step()            total_loss += loss.item() * inputs.size(0)            total_correct += torch.sum(predictions == labels.data)        epoch_loss = total_loss / len(train_loader.dataset)        epoch_acc = total_correct.double() / len(train_loader.dataset)        return epoch_loss, epoch_acc.item()    def valid(model, valid_loader,criterion):        model.train(False)        total_loss = 0.0        total_correct = 0        true = (torch.tensor([])).to(device)        pred = (torch.tensor([])).to(device)        for inputs, labels in valid_loader:            inputs = inputs.to(device)            labels = labels.to(device)            outputs = model(inputs)            loss = criterion(outputs, labels)            _, predictions = torch.max(outputs, 1)            total_loss += loss.item() * inputs.size(0)            total_correct += torch.sum(predictions == labels.data)            true = torch.cat((true,labels.data),0)            pred = torch.cat((pred,predictions),0)        epoch_loss = total_loss / len(valid_loader.dataset)        epoch_acc = total_correct.double() / len(valid_loader.dataset)        return epoch_loss, epoch_acc.item(), true, pred    best_acc = 0.0    base_epoch = 0    for epoch in range(base_epoch, base_epoch+num_epochs):        print('*' * 100)        print('epoch:{:d}/{:d}'.format(epoch, base_epoch + num_epochs))        train_loss, train_acc = train(model, train_loader,optimizer,criterion)        print("training: {:.8f}, {:.4f}".format(train_loss, train_acc))        valid_loss, valid_acc, valid_true, valid_pred= valid(model, valid_loader,criterion)        print("validation: {:.8f}, {:.4f}".format(valid_loss, valid_acc))        valid_true = valid_true.cpu()        valid_pred = valid_pred.cpu()        print("confusion_matrix: \n",confusion_matrix(valid_true,valid_pred))        if label2idxes is not None:            print("filtered confusion matrix: \n")            filtered_confusion_matrix(label2idxes, valid_true, valid_pred)        if writer != None:            writer.add_scalar('Loss/test', valid_loss, epoch)            writer.add_scalar('Loss/train', train_loss, epoch)            writer.add_scalar('Accuracy/test', valid_acc, epoch)            writer.add_scalar('Accuracy/train', train_acc, epoch)        if scheduler:            scheduler.step()        if valid_acc >= best_acc:            best_acc = valid_acc            best_model = model            best_cm = confusion_matrix(valid_true,valid_pred)            # if label2idxes is not None:            #     print("filtered confusion matrix: \n")            #     filtered_confusion_matrix(label2idxes, valid_true, valid_pred)            torch.save(best_model, 'best_model/{}.pt'.format(model_name))        if epoch%50 == 0:            torch.save(model, 'model/{}_epoch_{}.pt'.format(model_name, epoch))    print('*' * 100)    print('best acc: {:.4f}'.format(best_acc))    print("best confusion_matrix: \n", best_cm)def valid_model(model, valid_loader, criterion):    def valid(model, valid_loader,criterion):        model.train(False)        total_loss = 0.0        total_correct = 0        true = (torch.tensor([])).to(device)        pred = (torch.tensor([])).to(device)        for inputs, labels in valid_loader:            inputs = inputs.to(device)            labels = labels.to(device)            outputs= model(inputs)            loss = criterion(outputs, labels)            _, predictions = torch.max(outputs, 1)            total_loss += loss.item() * inputs.size(0)            total_correct += torch.sum(predictions == labels.data)            true = torch.cat((true,labels.data),0)            pred = torch.cat((pred,predictions),0)        epoch_loss = total_loss / len(valid_loader.dataset)        epoch_acc = total_correct.double() / len(valid_loader.dataset)        return epoch_loss, epoch_acc.item(), true, pred    valid_loss, valid_acc, valid_true, valid_pred = valid(model, valid_loader, criterion)    valid_true = valid_true.cpu()    valid_pred = valid_pred.cpu()    print("validation: {:.8f}, {:.4f}".format(valid_loss, valid_acc))    print("confusion_matrix: \n", confusion_matrix(valid_true, valid_pred))def setup_seed(seed):    torch.manual_seed(seed)    torch.cuda.manual_seed_all(seed)    np.random.seed(seed)    random.seed(seed)    torch.backends.cudnn.deterministic = Trueif __name__ == '__main__':    trainTransforms = transforms.Compose([        transforms.ToTensor(),        transforms.CenterCrop(size=64),    ])    validTransforms = transforms.Compose([        transforms.ToTensor(),        transforms.CenterCrop(size=64),    ])    train_data = Dataset('./data/SOC/train', transform=trainTransforms, percent=0.2)    valid_data = Dataset('./data/SOC/test', transform=validTransforms)    # for EOC    # valid_data = TestDataset('./data/EOC-C/test', transform=validTransforms)    # label2idxes = valid_data.label2idxes    BATCH_SIZE = 32    train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)    valid_loader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=False)    setup_seed(2)    # for train    model = cct_6_7x3_64_sine(num_classes = 10, n_input_channels = 1)    model = model.to(device)    # load encoder parameters    encoderState = torch.load('./conv_autoencoder.pth')    newState = OrderedDict()    newState['tokenizer.conv_layers.0.0.weight'] = encoderState['encoder1.0.weight']    newState['tokenizer.conv_layers.1.0.weight'] = encoderState['encoder2.0.weight']    modelState = model.state_dict()    modelState.update(newState)    model.load_state_dict(modelState)    # freeze loaded layer    sequential = model.tokenizer.children().__next__().children()    conv1 = sequential.__next__().children().__next__()    conv1.weight.requires_grad = False    conv2 = sequential.__next__().children().__next__()    conv2.weight.requires_grad = False    criterion = torch.nn.CrossEntropyLoss()    epoch = 100    lr = 0.001    # optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, momentum=0.9, weight_decay=1e-4)    optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, momentum=0.9)    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.8, last_epoch=-1)    writer = SummaryWriter('runs/MACT')    train_model(model, train_loader, valid_loader, criterion, optimizer, writer, num_epochs=epoch, scheduler=scheduler, model_name='MACT', label2idxes=None)    writer.close()