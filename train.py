import jsonimport osimport torchimport torch.utils.data as dataimport randomimport timefrom torch.utils.data import DataLoaderfrom torchvision.transforms import transformsfrom torch.utils.tensorboard import SummaryWriterfrom sklearn.metrics import confusion_matrixfrom PIL import Imagefrom collections import OrderedDictimport numpy as npfrom model_cct import cct_6_7x3_64_sine, cct_6_3x6_64_sine, cct_2_7x3_64_sine, cct_4_7x3_64_sinefrom model_cct.multiBranch import MultiBranchfrom noisyTransform import AddNoise, SaltPepperNoise, GaussianNoisefrom model_cct.BCRN import BCRNfrom model_cct.VDCNN import VDCNNfrom model_cct.MultiViewConformer import MultiViewConformerfrom fvcore.nn import FlopCountAnalysisfrom fvcore.nn import flop_count_tableos.environ["CUDA_VISIBLE_DEVICES"] = "0"device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")# device = 'cpu'imagebuffer = {}class Dataset(data.Dataset):    def __init__(self,path,transform = None, percent = 1.0, seed = 1):        self.path = path        self.transform = transform        self.image = []        # get label        self.class_names = sorted(os.listdir(path))        self.names2index = {v: k for k, v in enumerate(self.class_names)}        setup_seed(seed)        # read-in sequence and label        for label in self.class_names:            labelPath = os.path.join(path,label)            jsonpath = os.path.join(labelPath,"sequence.json")            with open(jsonpath, 'r', encoding='utf-8') as f:                sequence = json.load(f)            selectedSequence = np.random.choice(len(sequence), int(len(sequence)*percent), replace=False)            for i in selectedSequence:                self.image.append((sequence[i], self.names2index[label]))    def __len__(self):        return len(self.image)    def __getitem__(self, item):        path,label = self.image[item]        img = []        for i in range(0, len(path)):            if path[i] not in imagebuffer:                imagebuffer[path[i]] = Image.open(path[i])            tmp = imagebuffer[path[i]]            img.append(self.transform(tmp))        return torch.cat(tuple(img)).to(device), label# for EOC-C or EOC-V testclass TestDataset(data.Dataset):    def __init__(self,path,transform = None):        self.path = path        self.transform = transform        self.image = []        # get type        self.type_names = sorted(os.listdir(path))        self.names2index = {v: k for k, v in enumerate(self.type_names)}        self.label2idxes = {}        # read-in sequence and label        for type in self.type_names:            self.label2idxes[type] = []            typePath = os.path.join(path,type)            jsonpath = os.path.join(typePath,"sequence.json")            with open(jsonpath, 'r', encoding='utf-8') as f:                sequence = json.load(f)            # for EOC-C            if type == 'SN_9566' or type == 'SN_C21':                for i in range(0, len(sequence)):                    self.image.append((sequence[i], 0))                    self.label2idxes[type].append(len(self.image) - 1)            else:                for i in range(0, len(sequence)):                    self.image.append((sequence[i], 3))                    self.label2idxes[type].append(len(self.image)-1)            #for EOC-V            # for i in range(0, len(sequence)):            #     self.image.append((sequence[i], 3))            #     self.label2idxes[type].append(len(self.image) - 1)    def __len__(self):        return len(self.image)    def __getitem__(self, item):        path,label = self.image[item]        img = []        for i in range(0, len(path)):            if path[i] not in imagebuffer:                imagebuffer[path[i]] = Image.open(path[i])            tmp = imagebuffer[path[i]]            img.append(self.transform(tmp))        return torch.cat(tuple(img)), labeldef filtered_confusion_matrix(label2idxes, true, pred):    for label, idxes in label2idxes.items():        mpred = pred[idxes].numpy().astype(int)        values, counts = np.unique(mpred, return_counts=True)        print("\nlabel:{}({})".format(label, int(true[idxes[0]])))        for i in range(len(values)):            print("label:", values[i], "count:", counts[i], end=', ')        print("")def train_model(model,train_loader, valid_loader, criterion, optimizer, writer, num_epochs=20, scheduler = None, model_name = "", label2idxes = None):    def train(model, train_loader,optimizer,criterion):        model.train(True)        total_loss = 0.0        total_correct = 0        for inputs, labels in train_loader:            inputs = inputs.to(device)            labels = labels.to(device)            # flops = FlopCountAnalysis(model, inputs)            # print(flop_count_table(flops))            # print(flops.total())            optimizer.zero_grad()            # torch.cuda.synchronize()            # time_start = time.time()            outputs = model(inputs)            # torch.cuda.synchronize()            # time_end = time.time()            # time_sum = time_end - time_start            loss = criterion(outputs, labels)            _, predictions = torch.max(outputs, 1)            loss.backward()            optimizer.step()            total_loss += loss.item() * inputs.size(0)            total_correct += torch.sum(predictions == labels.data)        epoch_loss = total_loss / len(train_loader.dataset)        epoch_acc = total_correct.double() / len(train_loader.dataset)        return epoch_loss, epoch_acc.item()    def valid(model, valid_loader,criterion):        model.train(False)        total_loss = 0.0        total_correct = 0        true = (torch.tensor([])).to(device)        pred = (torch.tensor([])).to(device)        for inputs, labels in valid_loader:            inputs = inputs.to(device)            labels = labels.to(device)            # torch.cuda.synchronize()            # time_start = time.time()            outputs = model(inputs)            # torch.cuda.synchronize()            # time_end = time.time()            # time_sum = time_end - time_start            loss = criterion(outputs, labels)            _, predictions = torch.max(outputs, 1)            total_loss += loss.item() * inputs.size(0)            total_correct += torch.sum(predictions == labels.data)            true = torch.cat((true,labels.data),0)            pred = torch.cat((pred,predictions),0)        epoch_loss = total_loss / len(valid_loader.dataset)        epoch_acc = total_correct.double() / len(valid_loader.dataset)        # return epoch_loss, epoch_acc.item()        return epoch_loss, epoch_acc.item(), true, pred    best_acc = 0.0    base_epoch = 0    for epoch in range(base_epoch, base_epoch+num_epochs):        print('*' * 100)        print('epoch:{:d}/{:d}'.format(epoch, base_epoch + num_epochs))        train_loss, train_acc = train(model, train_loader,optimizer,criterion)        print("training: {:.8f}, {:.4f}".format(train_loss, train_acc))        valid_loss, valid_acc, valid_true, valid_pred= valid(model, valid_loader,criterion)        # valid_loss, valid_acc= valid(model, valid_loader, criterion)        print("validation: {:.8f}, {:.4f}".format(valid_loss, valid_acc))        valid_true = valid_true.cpu()        valid_pred = valid_pred.cpu()        print("confusion_matrix: \n",confusion_matrix(valid_true,valid_pred))        if label2idxes is not None:            print("filtered confusion matrix: \n")            filtered_confusion_matrix(label2idxes, valid_true, valid_pred)        if writer != None:            writer.add_scalar('Loss/test', valid_loss, epoch)            writer.add_scalar('Loss/train', train_loss, epoch)            writer.add_scalar('Accuracy/test', valid_acc, epoch)            writer.add_scalar('Accuracy/train', train_acc, epoch)        if scheduler:            scheduler.step()        if valid_acc >= best_acc:            best_acc = valid_acc            best_model = model            best_cm = confusion_matrix(valid_true,valid_pred)            # if label2idxes is not None:            #     print("filtered confusion matrix: \n")            #     filtered_confusion_matrix(label2idxes, valid_true, valid_pred)            torch.save(best_model, 'best_model/SOC/{}.pt'.format(model_name))        if epoch%50 == 0:            torch.save(model, 'model/SOC/{}_epoch_{}.pt'.format(model_name, epoch))    print('*' * 100)    print('best acc: {:.4f}'.format(best_acc))    print("best confusion_matrix: \n", best_cm)def valid_model(model, valid_loader, criterion):    def predict(outputs):        seq_len = int(outputs.shape[0])        predict_map = {}        max_label = -1        max_preds = []        for i in range(seq_len):            pred = int(torch.argmax(outputs[i]))            if pred not in predict_map:                predict_map[pred] = []            predict_map[pred].append(i)            if len(predict_map[pred]) > max_label:                max_label = pred                max_preds = [pred]            elif len(predict_map[pred]) == max_label:                max_preds.append(pred)        final_pred = -1        final_pred_score = 0        for pred in max_preds:            # average            score = outputs[predict_map[pred]].sum(axis=0).max()/seq_len            # max            # score = outputs[predict_map[pred]].max()            if score>final_pred_score:                final_pred_score = score                final_pred = pred        return int(final_pred)    def valid(model, valid_loader,criterion):        model.train(False)        total_loss = 0.0        total_correct = 0        true = (torch.tensor([])).to(device)        pred = (torch.tensor([])).to(device)        for inputs, labels in valid_loader:            inputs = inputs.to(device)            labels = labels.to(device)            # _,outputs = model(inputs)            # torch.cuda.synchronize()            # time_start = time.time()            outputs= model(inputs)            # torch.cuda.synchronize()            # time_end = time.time()            # time_sum = time_end - time_start            # predictions = torch.Tensor(np.array([predict(output) for output in outputs])).to(device)            loss = criterion(outputs, labels)            _, predictions = torch.max(outputs, 1)            total_loss += loss.item() * inputs.size(0)            total_correct += torch.sum(predictions == labels.data)            true = torch.cat((true,labels.data),0)            pred = torch.cat((pred,predictions),0)        epoch_loss = total_loss / len(valid_loader.dataset)        epoch_acc = total_correct.double() / len(valid_loader.dataset)        # return epoch_loss, epoch_acc.item()        return epoch_loss, epoch_acc.item(), true, pred    valid_loss, valid_acc, valid_true, valid_pred = valid(model, valid_loader, criterion)    valid_true = valid_true.cpu()    valid_pred = valid_pred.cpu()    print("validation: {:.8f}, {:.4f}".format(valid_loss, valid_acc))    print("confusion_matrix: \n", confusion_matrix(valid_true, valid_pred))def setup_seed(seed):    torch.manual_seed(seed)    torch.cuda.manual_seed_all(seed)    np.random.seed(seed)    random.seed(seed)    torch.backends.cudnn.deterministic = Trueif __name__ == '__main__':    trainTransforms = transforms.Compose([        # transforms.RandomResizedCrop(64, scale=(0.9, 1.0), ratio=(0.9, 1.1)),        # transforms.RandomHorizontalFlip(),        transforms.ToTensor(),        # transforms.RandomCrop(68),        transforms.CenterCrop(size=64),        # transforms.Resize([90, 90]),    ])    validTransforms = transforms.Compose([        # transforms.RandomResizedCrop(64, scale=(0.9, 1.0), ratio=(0.9, 1.1)),        # transforms.RandomHorizontalFlip(),        transforms.ToTensor(),        # GaussianNoise(noise_rate=0.01),        transforms.CenterCrop(size=64),        # transforms.Resize([90, 90]),    ])    # train_data = Dataset('./data/SOC-128/train', transform=trainTransforms, percent=0.2)    # valid_data = Dataset('./data/SOC-128/test', transform=validTransforms)    # valid_data = TestDataset('./data/EOC-C/test', transform=validTransforms)    # label2idxes = valid_data.label2idxes    BATCH_SIZE = 32    # train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)    # valid_loader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=False)    setup_seed(2)    # for train    # model = cct_6_7x3_64_sine(num_classes = 10, n_input_channels = 1)    # model = cct_6_3x6_64_sine(num_classes=10, n_input_channels=1)    # model = MultiViewConformer(n_input_size=64, n_input_channels=1, n_output_channels=256)    # model = BCRN(num_classes = 10)    # model = VDCNN(num_classes = 10)    # for test    # model = torch.load('best_model/SOC/seed2_cct_6_7x3_64_sine_15.pt')    # model = torch.load('best_model/SOC/seed2_cct_6_7x3_64_sine_11.pt')    # model = torch.load('best_model/SOC/BCRN.pt')    # model = torch.load('model/SOC/MVDCNN_2_epoch_50.pt')    model = torch.load('best_model/SOC/MultiViewTransformer_8.pt')    model = model.to(device)    # valid_model(model, valid_loader, None)    # load encoder parameters    # encoderState = torch.load('./best_model/conv_autoencoder.pth')    # newState = OrderedDict()    # newState['tokenizer.conv_layers.0.0.weight'] = encoderState['encoder1.0.weight']    # newState['tokenizer.conv_layers.1.0.weight'] = encoderState['encoder2.0.weight']    # modelState = model.state_dict()    # modelState.update(newState)    # model.load_state_dict(modelState)    # # freeze loaded layer    # sequential = model.tokenizer.children().__next__().children()    # conv1 = sequential.__next__().children().__next__()    # conv1.weight.requires_grad = False    # conv2 = sequential.__next__().children().__next__()    # conv2.weight.requires_grad = False    criterion = torch.nn.CrossEntropyLoss()    # epoch = 100    # lr = 0.001    # # optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, momentum=0.9, weight_decay=1e-4)    # optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, momentum=0.9)    # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.8, last_epoch=-1)    # # milestones=[10,30]    # # scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones, gamma=0.1, last_epoch=-1)    # writer = SummaryWriter('runs/SOC/MultiViewTransformer_7_0.1')    # train_model(model, train_loader, valid_loader, criterion, optimizer, writer, num_epochs=epoch, scheduler=None, model_name='MultiViewTransformer_7_0.1', label2idxes=None)    # writer.close()    # for noise-test    for seed in [2]:        print("seed =", seed)        for noise_rate_idx in range(5):            noise_rate = (noise_rate_idx+0)/100            validTransforms = transforms.Compose([                # transforms.Resize([224, 224]),                # transforms.RandomResizedCrop(64, scale=(0.9, 1.0), ratio=(0.9, 1.1)),                # transforms.RandomHorizontalFlip(),                transforms.ToTensor(),                GaussianNoise(var=noise_rate),                transforms.CenterCrop(size=64),                # transforms.Resize([90, 90]),            ])            setup_seed(seed)            valid_data = Dataset('./data/SOC-128/test', transform=validTransforms)            valid_loader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=False)            print("=========================================")            print("noise_rate =", noise_rate, "seed =", seed)            valid_model(model, valid_loader, criterion)            print("=========================================\n\n")